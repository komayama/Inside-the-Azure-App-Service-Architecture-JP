# Azure App Service アーキテクチャの内部

Azure App Service は優れた Platform as a Service (PaaS) で開発者が Web、モバイルそして API アプリケーションを構築するためにアプリケーションプラットフォームを提供しております。シンプルなマーケティングやデジタル展開するアプリケーションから、拡張性がある e-コマースソリューションやハイパースケールでカスタマイズ可能なアプリケーションまで及びます。

App Service はフルマネージドです。つまり、アプリケーションを実行するためのインフラ（サーバ）を管理する業務はございません。OS プラットフォームやフレームワークのパッチをサーバに適用しメンテナンスをする必要の心配はございません。アプリケーションは仮想サーバ上にて動作しますが、アプリケーションを動かすためのサーバインスタンスの最大値を設定するのみ注意する必要があります。プラットフォームでは、アプリケーションにて複数のサーバインスタンスを必要とする場合にスケーリングをすると同時に、ロードバランサがトラフィックを複数のインスタンスへ振り分けます。

App Service チームは実装の詳細を隠すようにしておりますが、内部でどのように機能するか知ることが良いでしょう。この記事では、Web Apps の基本的な内部アーキテクチャ（どのようなサービスが起動し動作するか）や特定のシナリオにおけるベストプラクティスを提供します。

## グローバルと地理的分散のアーキテクチャ

クラウドコンピューティングは早くスケールを行い、限りないキャパシティを持っています。クラウドのスケールは、PC 画面の動きと同様の説明をすることができます。PC の画面を遠くから見ると、鮮明になめらかな画像を見ることができます。近くにて見ると、多くの小さなピクセルとして構成されています。クラウドも画像と同様で、多くのサーバによって構成されています。App Service は、サーバの束を "スケールユニット" と呼ばれる １ つのクラスタとします。Azure データセンター内には、世界中にそのようなスケールユニットが多くございます。

Azure の一部として、App Service は世界中に拠点があります。Azure がサポートする全てのリージョンには、お客様のワークロード（アプリケーション）を実行する App Service スケールユニットとリージョナルコントロールユニットのセットがあります。コントロールユニットはお客様に対して（誤動作が発生するまで）わかりやすく、プラットフォームの一部として動作します。全ての API 呼び出しゲートウェイとして使用されている特別なコントロールユニットがあります。例えば、お客様が Azure Portal を介したり、コマンドラインインターフェイスもしくは直接 Azure REST API を使用して新しいアプリケーションを作成をリクエストした際に、そのリクエストは主要の Azure エンドポイント (management.azure.com) へルーティングされます。Azure Resource Manager, もしくは ARM (bit.ly/2i6UD07) はお客様のアプリケーション内の様々な Azure リソースを単一のグループとして操作できます。ARM によって定義された API を利用すると Azure リソースを管理できます。ARM は実際に個別のリソースを管理できません。Azure の各サービスは独自の API 実装をしておりますが、ARM により API 呼び出しを委任しております。App Service の場合、ARM は App Service API の呼び出しを App Service Geo-マスター へ転送します。

Geo-マスター は世界中全てのスケールユニットという意味があります。例えば、新しい App Service アプリケーション（もしくは Web サイト）を作成する時に、Geo-マスター は最も適したスケールユニットを探し、その後、作成要求に適したスケールユニットへ転送します。スケールユニットは、新しいアプリケーションのプロビジョニングとアプリケーションに必要なリソースの割り当てを実施します、図 1 は新しいアプリケーションを作成中について示しております。

（図）

図 1: App Service スケールユニットのグローバルディストリビューション

新しいアプリケーションを作成する処理は以下の通りです。

1. ユーザが新しいサイトを作成するためのリクエストをします
2. ARM はユーザの操作を許可（今回は作成）するためにリソースへアクセスできることを確認し、リクエストを Geo-マスター へ転送します
3. Geo-マスター は、ユーザから転送されたリクエストにて一番適したスケールユニットを探します
4. スケールユニットは新しいアプリケーションを作成します
5. Geo-マスター はアプリケーション作成リクエストが成功したことを通知します

App Service は多くのスケールユニットがあることを理解することが重要ですが、アプリケーションは単一の App Service スケールユニット内で実行されます。Azure Traffic Manager を使用して複数のリージョンで実行したとしても、アプリケーションは ２ つ以上のスケールユニットで実行されます。しかしながら、個々のスケールユニットの観点からは、アプリケーションは 1 つのスケールユニットに制限されます。

## App Service スケールユニットとは？

App Service スケールユニットとはアプリケーションをホストおよび実行するサーバをまとめたものです。一般的なスケールユニットは、1000 以上のサーバを持っています。サーバをクラスタリングしたことにより、スケールの効率的使用やインフラストラクチャの再利用が可能となります。App Service スケールユニットの基本的な構成要素は、Azure Cloud Service デプロイメントです。（App Service は、2012 年 6 月にプレビュー版としてリリースされました。）どのスケールユニットも自律的であり、単独で動作します。

## スケールユニットの主要な構成要素

スケールユニットの主な機能はお客様のアプリケーションをホストし実行することです。アプリケーションは Windows サーバ上で実行され、Web Worker、Worker と呼ばれています。スケールユニット内のサーバの大部分は、Worker となります。しかしながら、スケールの単位では、App Service によって提供される機能を実現するために必要な追加のサポートサーバが含まれています。サポートサーバは role を持っており、各 Role は冗長性と拡張性のために複数のインスタンス上にデプロイされます。

## FrontEnd

FrontEnd は、レイヤー (OSI レイヤー 7) 、プロキシとしての振る舞いをし、異なるアプリケーションとそれぞれの Worker 間で HTTP リクエストの呼び出しを分散させます。現在、App Service ロードバランサのアルゴリズムは、特定のアプリケーションに割り当てたサーバ間にて、単純なラウンドロビンとしております。

## Web Workers

複数の Worker は、App Service スケールユニットのバックボーンでございます。お客様自身のアプリケーションを実行することができます。

App Service を使用することで、アプリケーションの実行方法を選択することができます。共有サーバまたは専用サーバ上にてアプリケーションを実行を選択することができます。これを行うには、App Service Plan にて選択します。App Service Plan は一連の性能、機能やサーバへの割り当てを定義することができます。共有 Worker は複数の異なるお客様にてアプリケーションをホストをし、専用 Worker は 1 人のお客様にて、1つ 以上のアプリケーションを実行することが保証されております。複数の専用サーバの種類やサイズがあり、お客様より選択可能です。大きなサーバのサイズは、アプリケーションに割り当てるために、より多くの CPU や メモリのリソースが利用可能です。App Service Plan は、アプリケーションに対して事前に割り当てられたサーバの数を定義します。

App Service スケールユニットは、事前にプロビジョニングされた Workers のプールがいくつかあり、お客様のアプリケーションをホストする準備をしているのを 図 2 のセクション 1 に示しております。専用の App Service Plan で 2 台のサーバサイズを定義をすると、図 2 のセクション 2 に示しますように App Sercice は 2 台のサーバを割り当てます。次に、お客様の App Service Plan にてスケールアウトをすると（例えば、さらに 2 つの Worker を追加をする）、図 2 のセクション 3 に示すように、利用可能な Worker は即座に使用できる Worker のプールから割り当てられます。Worker は事前にプロビジョニングしウォームスタンバイであるので、アプリケーションを Worker へデプロイするだけとなっております。アプリケーションがデプロイされると、Worker はローテーションに入り、FrontEnd がアプリにトラフィックを割り当てます。これらのプロセス全体は通常、数秒かかります。

（図）

図 2: App Service スケールユニット内のサーバアプリケーション処理

図 2 のセクション 4 では、複数の色や四角で囲まれている App Service Plan を示しております。複数のお客様によって Worker のプールを共有している App Service Plan を表しております。

## File Servers

複数のアプリケーションは、HTML、js ファイル、画像、コードファイルなどのコンテンツやアプリケーションが機能するためのコンテンツを保持するためにストレージが必要となります。ファイルサーバは Azure Storage blob をマウントし、ネットワークドライブとして Worker へ公開します。Worker はそのネットワークドライブをローカルとしてマッピングし、アプリケーションがローカルディスクを使用するサーバで実行されている場合と同様にして、Worker で実行されているアプリケーションは "ローカル" ドライブとして使用できます。アプリケーションによって実行されるファイルに関する読み取り/書き込みはすべてファイルサーバを通しています。

## API Contorollers

API Contorollers は、App Service Geo-マスター の拡張機能としております。Geo-マスター は、すべての スケールユニットにわたる App Servie アプリケーションを認識しており、アプリケーションに影響を与える管理操作を実際に実行しているのが、API コントローラーになります。Geo-マスター は、API Controllers を返して API の実行をスケールユニットに委任します。例えば、Geo-マスター が API を呼び出して新しいアプリケーションを作成すると、API Controller がスケールユニットにてアプリケーションを作成するために必要な手順を行います。アプリケーションのリセットを Azure Portal を使用したときに、アプリケーションに現在割り当てられている Web Worker を再起動するように通知を行うのが、API Contoroller です。

## Publisher

Azure App Service は、アプリケーションへの FTP アクセスをサポートしています。アプリケーションのコンテンツは Azure Storage blobs と ファイルサーバによってマッピングされているため、App Service は、FTP 機能を公開する Publisher ロールを持っています。Publisher ロールにより、お客様は FTP を使用しアプリケーションコンテンツやログへアクセスすることができます。

アプリケーションのデプロイは FTP 以外にも存在しているため注意する必要がございます。一般的なデプロイ方法は Web Deploy （Visual Studio から）もしくはVisual Studio Release Manager や GitHub のような継続的デプロイがサポートされています。

## SQL Azure

各 App Service スケールユニットは、アプリケーションのメタデータを永続化するために Azure SQL Database を使用します。スケール単位に割り当てられている各アプリケーションには、SQL データベース内にて表現されています。SQL データベースはに関するランタイム情報を保持するためにも使用されます。

## Data Role

すべての role が機能するには、データベースにあるデータが必要です。例として：Web Worker は、サイトの構成情報を必要とします。FrontEnd は、HTTPリクエストを適切なサーバへ転送するために、特定のアプリケーション実行している割り当てられたサーバを知る必要があります。Controller は、お客様が実行した API 呼び出しに基づいて、データベースからデータを読み取り、更新を行います。Data Role は、SQL データベースとスケールユニット内にある他の Role 間のキャッシュレイヤーとしております。他の Role からデータ層（SQL データベース）を抽象化し、スケールとパフォーマンスをを控除させ、ソフトウェア開発やメンテナンスを簡素化します。

## あまり知られていないベストプラクティス

Azure App Service の構築方法を知ったところで、App Service チームからのヒントとコツを確認していきます。これらは、App Service エンジニアリングチームが多くのお客様のエンゲージメントから学んだ実践的な教訓です。

## 密度のコントロール

多くのお客様は 1 つの App Service Plan にて少数（10 未満）のアプリケーションを実行しています。しかしながら、お客様はより多くのアプリケーションを実行するシナリオが多く存在します。基盤となるサーバの容量を誤って飽和させないことが重要となります。

アプリケーションとコンピューティングリソースの基本的な階層から始めていきましょう。App Service Plan に関連付けられている 2 つの Web アプリケーションと 1 つのモバイルバックエンドがあります。

デフォルトでは、App Service Plan に含まれるすべてのアプリケーションは、その Service Plan に割り当てられた利用可能なコンピューティングリソース（サーバ）で実行されます。3 つのアプリケーションはすべて、二つのサーバで実行されます。App Service Plan に単一のサーバがあるケースでは、理解することは簡単です。App Service Plan のすべてのアプリケーションは単一のサーバで実行します。

App Service Plan に複数のコンピューティングリソースが割り当てられている場合に何が発生するかについては、やや直感的ではありません。例として、単一の App Service Plan に 10 個のコンピュートリソースがある場合に、その後すべてのアプリケーションが全てのコンピュートリソースで実行されます。もし、50 個のアプリケーションが App Service Plan にある場合に、50 個の全てのアプリケーションが最初のサーバで実行され、同じ 50 個が 2番目のサーバで実行され、以下同様にして 10 番目のサーバで実行されます。 10 番目のサーバも 50 個全てのアプリケーションを実行します。

一部のシナリオでは、アプリケーションが大量のコンピューティングリソースを必要とする場合、通常は HTTP リクエストの増加を処理するために、利用可能な全てのサーバ上でアプリケーションを実行する必要があります。しかしながら、App Service olan が 1 つのサーバから多くのサーバへスケールアウトされた時に意図しない結果である場合があります。多くのアプリケーションの実行によって、App Service Plan が CPU やメモリの負荷にさらされている場合は、その App Service Plan にてサーバの数を増加しても問題は解決されません。

代わりに、各アプリケーションのトラフィック分散を考慮し、容量が少ないアプリケーションのロングテールとなっているものを個別の App Service Plan へ分割をします。個別のを App Service Plan にて、容量の大きいアプリケーションを実行することを考慮ください。前回の 50 個のアプリケーションの例を使用しますと、トラフィックパターンを分析した後、App Service Plan とコンピューティングリソースに次のように割り当てることができます。

* 40 個の容量が少ないアプリケーションを、1 つのコンピューティングリソース上の単一の App Service Planに残します。
* 5 個の中〜低容量のアプリケーションを、1 つのコンピューティングリソース上で実行される 2 番目の App Service Plan を使用します。
* 残りの 5 個のアプリケーションは、容量を多く使用していることが分かりました。各アプリケーションは、個別の App Service Plan へデプロイします。オートスケールルールは、CPU とメモリの使用率に基づいてスケールイン/アウトすルールを設定し、最低でも 1 つのコンピューティングリソースを使用する App Service Plan を設定します。

この手法の最終的な結果は、50 個のアプリケーションは最低でも 7つのコンピューティングリソースを使用し、5 個の容量の大きいアプリケーションは負荷に基づいてオンデマンドで個別にスケールアウトするために必要な App Service Plan があります。
